<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
  <script src="localforage/dist/localforage.js"></script>
  <style>
    body {
      margin: 0;
      padding: 0;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      background-color: rgb(61,58,53);
    }

    canvas {
      position: absolute;
    }
    .flexbox {
      display: flex;
      flew-wrap: wrap;
      justify-content: center;
      align-items: center;
    }
    .silueta{
      width:300px;
      height:350px;
      position:absolute;
      top:50%;
      left:50%;
      transform:translate(-50%,-50%);
      }
      .boton{
        width: 70px;
        height: 85px;
        background-size: cover !important;
        border:0;
      }

    /*.sidebar{
        width:400px;
    }*/
    
    .center{
        text-align:center;
    }
    
    .center button{
        display:inline-block;
        margin-left:30px;
        margin-right:30px; 
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="row"> 
      <div class="col s3"></div>
      <div class="col s6">
      <div class="progress" id="loader">
        <div class="indeterminate"></div>
      </div>
      <div style="position: relative; overflow: auto" id="imagenCapturada" class="">
        <!-- <canvas id="canvas" style="overflow:auto"></canvas>
        
        <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
        <canvas id="overlay"> -->
      </div>
      <!-- <img class="silueta" src="contorno.png"/> -->

    </div>
    <div class="col s3"></div>
      <!-- <div class="rectangle"></div> -->
    </div>   
    <div class="row">
      <div class="col s3"></div>
      <div class="col s6">
        <div class="center">
          <button class="boton" onclick="capture()"  style="background: url('cancelar.png')"  id="cancelar"></button> 
          <button class="boton" onclick="capture()" style="background: url('circulo.png')" id="capturar"></button> 
          <button class="boton" onclick="capture()" style="background: url('saltar.png')" id="saltar"></button>  
        </div>
  </div>
  <div class="col s3"></div> 

      </div>
  </div>

  <script  src="server.js"></script>
  </body>
  <script>
    let forwardTimes = []
    let withBoxes = true

    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      $('#time').val(`${Math.round(avgTimeInMs)} ms`)
      $('#fps').val(`${faceapi.utils.round(1000 / avgTimeInMs)}`)
    }

    async function onPlay() {
      const videoEl = $('#inputVideo').get(0)

      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())


      const options = getFaceDetectorOptions()

      const ts = Date.now()

      const result = await faceapi.detectSingleFace(videoEl, options).withFaceExpressions()

      updateTimeStats(Date.now() - ts)

      if (result) {
        const canvas = $('#overlay').get(0)
        const dims = faceapi.matchDimensions(canvas, videoEl, true)

        const resizedResult = faceapi.resizeResults(result, dims)
        const minConfidence = 0.05
        if (withBoxes) {
          faceapi.draw.drawDetections(canvas, resizedResult)
        }
        //if(JSON.stringify(resizedResult.expressions.happy )> 0.95){
          //$('#capturar').get(0).style.display = "block";
        //}
        //else{
         // $('#capturar').get(0).style.display = "none";
       // }
        // faceapi.draw.drawFaceExpressions(canvas, resizedResult, minConfidence) lo comento pero tb se puede dejar
      }

      setTimeout(() => onPlay())
    }

    async function run() {
      // load face detection and face expression recognition models
      await changeFaceDetector(TINY_FACE_DETECTOR)
      await faceapi.loadFaceExpressionModel('/')
      changeInputSize(224)

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream
    }

    function updateResults() {}

    $(document).ready(function() {
      initFaceDetectionControls()
      run()
      insertarImagen()
    })

    function insertarImagen(){
      var img = document.createElement("img");
img.src = localStorage.getItem("imagen");
var src = document.getElementById("imagenCapturada");
src.appendChild(img);
    }
    
    function capture() {
      console.log("llega de tomarfoto"+localStorage.getItem("imagen"));
      var canvas = document.getElementById("canvas");
      var video = document.querySelector("video");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
       canvas
        .getContext("2d")
        .drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
 
      /** Code to merge image **/
      /** For instance, if I want to merge a play image on center of existing image **/
      /** const playImage = new Image();
      playImage.src = localStorage.getItem("imagen"); //Ver que poner acÃ¡
      playImage.onload = () => {
        const startX = video.videoWidth / 2 - playImage.width / 2;
        const startY = video.videoHeight / 2 - playImage.height / 2;
        canvas
          .getContext("2d")
          .drawImage(playImage, startX, startY, playImage.width, playImage.height);
        canvas.toBlob() = (blob) => {
          const img = new Image();
          img.src = window.URL.createObjectUrl(blob);
        };
      }; **/
    /** End **/
  }
  
  capture();
  
  
  // video.addEventListener('play', () => {
  //   const canvas = faceapi.createCanvasFromMedia(video)
  //   document.body.append(canvas)
  //   const displaySize = { width: video.width, height: video.height }
  
  //    faceapi.matchDimensions(canvas, displaySize)
  //   setInterval(async () => {
  //     const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions()
  //     const resizedDetections = faceapi.resizeResults(detections, displaySize)
  //     canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
  //      faceapi.draw.drawDetections(canvas, resizedDetections)
  //     faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)
  //     faceapi.draw.drawFaceExpressions(canvas, resizedDetections)
  //     console.log(resizedDetections.length + resizedDetections[0].detection.score + resizedDetections[0].expressions.happy )
  //     if (resizedDetections.length > 0 && resizedDetections[0].detection.score > 0.7 && resizedDetections[0].expressions.happy > 0.5) {
  //       const canvas = document.createElement('canvas');
  //           canvas.width = video.videoWidth;
  //           canvas.height = video.videoHeight;
  //           canvas.getContext('2d').drawImage(video, 0, 0);
        
  //           const img = document.createElement("img");
  //           img.src = canvas.toDataURL('image/webp');
  //           console.log(img)
  //           document.getElementById('screenshot').appendChild(img)
  //     }
  //   }, 100)
  // })
  </script>
</body>
</html